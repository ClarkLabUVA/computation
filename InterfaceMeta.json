[{
  "interface":"nipype.interfaces.fsl.preprocess.MCFLIRT",
  "name":"FSL MCFLIRT",
  "description":"MCFLIRT is an intra-modal motion correction tool designed for use on fMRI time series and based on optimization and registration techniques used in FLIRT, a fully automated robust and accurate tool for linear (affine) inter- and inter-modal brain image registration.",
  "citation":"Jenkinson, M., Bannister, P., Brady, J. M. and Smith, S. M. Improved Optimisation for the Robust and Accurate Linear Registration and MotionCorrection of Brain Images. NeuroImage, 17(2), 825-841, 2002.",
},
{
  "interface":"nipype.interfaces.io.SelectFiles",
  "name":"IO SelectFiles",
  "description":"This interface uses Python's {}-based string formatting syntax to plug values (possibly known only at workflow execution time) into string templates and collect files from persistant storage.",
},
{
  "interface":"nipype.interfaces.fsl.utils.ExtractROI",
  "name":"FSL ExtractROI",
  "description":"extract region of interest (ROI) from an image. You can a) take a 3D ROI from a 3D data set (or if it is 4D, the same ROI is taken from each time point and a new 4D data set is created), b) extract just some time points from a 4D data set, or c) control time and space limits to the ROI. Note that the arguments are minimum index and size (not maximum index). So to extract voxels 10 to 12 inclusive you would specify 10 and 3 (not 10 and 12).",
  "citation":"M.W. Woolrich, S. Jbabdi, B. Patenaude, M. Chappell, S. Makni, T. Behrens, C. Beckmann, M. Jenkinson, S.M. Smith. Bayesian analysis of neuroimaging data in FSL. NeuroImage, 45:S173-86, 2009",
},
{
  "interface":"nipype.interfaces.fsl.preprocess.SliceTimer",
  "name":"FSL SliceTimer",
  "description":"slicetimer is a pre-processing tool designed to correct for sampling offsets inherent in slice-wise EPI acquisition sequences.",
},
{
  "interface":"nipype.algorithms.rapidart.ArtifactDetect",
  "name":"Algorithm ArtifactDetect",
  "description":"ArtifactDetect: performs artifact detection on functional images",
},
{
  "interface":"nipype.interfaces.fsl.preprocess.BET",
  "name":"FSL BET",
  "description":"BET (Brain Extraction Tool) deletes non-brain tissue from an image of the whole head. It can also estimate the inner and outer skull surfaces, and outer scalp surface, if you have good quality T1 and T2 input images.",
  "citation":"S.M. Smith. Fast robust automated brain extraction. Human Brain Mapping, 17(3):143-155, November 2002.",
},
{
  "interface":"nipype.interfaces.fsl.preprocess.FLIRT",
  "name":"FSL FLIRT",
  "description":"FLIRT (FMRIB's Linear Image Registration Tool) is a fully automated robust and accurate tool for linear (affine) intra- and inter-modal brain image registration.",
  "citation":["M. Jenkinson and S.M. Smith. A global optimisation method for robust affine registration of brain images. Medical Image Analysis, 5(2):143-156, 2001.","M. Jenkinson, P.R. Bannister, J.M. Brady, and S.M. Smith. Improved optimisation for the robust and accurate linear registration and motion correction of brain images. NeuroImage, 17(2):825-841, 2002. "],
},
{
  "interface":"nipype.interfaces.fsl.preprocess.FAST",
  "name":"FSL FAST",
  "description":"FAST (FMRIBs Automated Segmentation Tool) segments a 3D image of the brain into different tissue types (Grey Matter, White Matter, CSF, etc.), whilst also correcting for spatial intensity variations (also known as bias field or RF inhomogeneities). The underlying method is based on a hidden Markov random field model and an associated Expectation-Maximization algorithm. The whole process is fully automated and can also produce a bias field-corrected input image and a probabilistic and/or partial volume tissue segmentation. It is robust and reliable, compared to most finite mixture model-based methods, which are sensitive to noise.",
  "citation":"Zhang, Y. and Brady, M. and Smith, S. Segmentation of brain MR images through a hidden Markov random field model and the expectation-maximization algorithm. IEEE Trans Med Imag, 20(1):45-57, 2001.",
},
{
  "interface":"nipype.interfaces.fsl.maths.Threshold",
  "name":"FSL Threshold",
  "description":"use following number to threshold current image (zero anything below the number)",
},
{
  "interface":"nipype.interfaces.io.DataSink",
  "name":"IO DataSink",
  "description":"DataSink: Generic named output from interfaces to data store",
},
{
  "interface":"nipype.interfaces.spm.preprocess.Smooth",
  "name":"SPM Smooth",
  "description":"Smooth (ie convolve) image volumes with a Gaussian kernel of a specified width. It is used as a preprocessing step to suppress noise and effects due to residual differences in functional and gyral anatomy during inter-subject averaging.",
  "citation":"SPM12 Manual",
},
{
  "interface":"nipype.algorithms.modelgen.SpecifySPMModel",
  "name":"Specify SPM Model",
  "description":"Specifiy SPM Model parameters",
},
{
  "interface":"nipype.interfaces.spm.model.EstimateContrast",
  "name":"SPM Estimate Contrast",
  "description":"Use spm_contrasts to estimate contrasts of interest",
},
{
  "interface":"nipype.interfaces.spm.model.Level1Design",
  "name":"SPM Level1Design",
  "description":"Generate an SPM design matrix",
},
{
  "interface":"nipype.interfaces.utility.wrappers.Function",
  "name":"User Defined Function",
  "description":"See parameters for function defition. User defined function.",
},],

{
  "interface":"nipype.interfaces.fsl.preprocess.FNIRT",
  "name":"FSL FNIRT",
  "description":"FNIRT is used to calculate a non-linear registration from a source image to a reference image.",
}
{
  "interface":"nipype.interfaces.fsl.preprocess.ApplyWarp",
  "name":"FSL FNIRT ApplyWarp",
  "description":"Applies warp to FNIRTed Image",
}
{
  "interface":"nipype.interfaces.fsl.preprocess.SUSAN",
  "name":"FSL SUSAN",
  "description":"SUSAN noise reduction uses nonlinear filtering to reduce noise in an image (2D or 3D) whilst preserving the underlying structure. It does this by only averaging a voxel with local voxels which have similar intensity.",
}
{
  "interface":"nipype.interfaces.fsl.preprocess.FUGUE",
  "name":"FSL FUGUE",
  "description":"FUGUE is, most generally, a set of tools for EPI distortion correction. It also refers to a specific command line tool fugue.",
}
{
  "interface":"nipype.interfaces.fsl.preprocess.PRELUDE",
  "name":"FSL PRELUDE",
  "description":"prelude ( Phase Region Expanding Labeller for Unwrapping Discrete Estimates ) performs 3D phase unwrapping of images. As the name implies, it should be run before fugue in order to get a correct fieldmap. This is useful for fieldmap acquisitions, susceptibility weighted imaging (SWI), or other applications involving phase in MR (or non-MR) images. The input can either be a single complex image (NIfTI or Analyze), or a pair of real images giving the phase and absolute values separately. Also see Fslutils for more ways to manipulate complex image formats. If the images are 4D images, then each 3D volume is unwrapped separately, and the result saved as a 4D image of unwrapped phase images. The output in either case is a real, unwrapped phase image (in radians).",
}
{
  "interface":"nipype.interfaces.fsl.preprocess.FIRST",
  "name":"FSL FIRST",
  "description":"FIRST is a model-based segmentation/registration tool. The shape/appearance models used in FIRST are constructed from manually segmented images provided by the Center for Morphometric Analysis (CMA), MGH, Boston. The manual labels are parameterized as surface meshes and modelled as a point distribution model. Deformable surfaces are used to automatically parameterize the volumetric labels in terms of meshes; the deformable surfaces are constrained to preserve vertex correspondence across the training data. Furthermore, normalized intensities along the surface normals are sampled and modelled. The shape and appearance model is based on multivariate Gaussian assumptions. Shape is then expressed as a mean with modes of variation (principal components). Based on our learned models, FIRST searches through linear combinations of shape modes of variation for the most probable shape instance given the observed intensities in a T1-weighted image.",
}
{
  "interface":"nipype.interfaces.fsl.maths.StdImage",
  "name":"FSL Maths StdImage",
  "description":"Use fslmaths to generate a standard deviation in an image across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.MeanImage",
  "name":"FSL Maths MeanImage",
  "description":"Use fslmaths to generate a mean image across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.MaxImage",
  "name":"FSL Maths MaxImage",
  "description":"Use fslmaths to generate a max image across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.PercentileImage",
  "name":"FSL Maths PercentileImage",
  "description":"Use fslmaths to generate a Percentile image across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.MaxnImage",
  "name":"FSL Maths MaxnImage",
  "description":"Use fslmaths to generate an image of index of max across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.MinImage",
  "name":"FSL Maths MinImage",
  "description":"Use fslmaths to generate a min image across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.MedianImage",
  "name":"FSL Maths MedianImage",
  "description":"Use fslmaths to generate a median image across a given dimension.",
}
{
  "interface":"nipype.interfaces.fsl.maths.AR1Image",
  "name":"FSL Maths AR1Image",
  "description":"Use fslmaths to generate an AR1 coefficient image across a given dimension. (Should use -odt float and probably demean first)",
}
{
  "interface":"nipype.interfaces.fsl.maths.IsotropicSmooth",
  "name":"FSL Maths IsotropicSmooth",
  "description":"Use fslmaths to spatially smooth an image with a gaussian kernel.",
}
{
  "interface":"nipype.interfaces.fsl.maths.ApplyMask",
  "name":"FSL Maths ApplyMask",
  "description":"Use fslmaths to apply a binary mask to another image.",
}
{
  "interface":"nipype.interfaces.fsl.maths.DilateImage",
  "name":"FSL Maths DilateImage",
  "description":"Use fslmaths to perform a spatial dilation of an image.",
}
{
  "interface":"nipype.interfaces.fsl.maths.ErodeImage",
  "name":"FSL Maths ErodeImage",
  "description":"UUse fslmaths to perform a spatial erosion of an image..",
}
{
  "interface":"nipype.interfaces.fsl.maths.SpatialFilter",
  "name":"FSL Maths SpatialFilter",
  "description":"Use fslmaths to spatially filter an image.",
}
{
  "interface":"nipype.interfaces.fsl.maths.UnaryMaths",
  "name":"FSL Maths UnaryMaths",
  "description":"Use fslmaths to perorm a variety of mathematical operations on an image.",
}
{
  "interface":"nipype.interfaces.fsl.maths.BinaryMaths",
  "name":"FSL Maths BinaryMaths",
  "description":"Use fslmaths to perform mathematical operations using a second image or a numeric value.",
}
{
  "interface":"nipype.interfaces.fsl.maths.MultiImageMaths",
  "name":"FSL Maths MultiImageMaths",
  "description":"Use fslmaths to perform a sequence of mathematical operations.",
}
{
  "interface":"nipype.interfaces.fsl.maths.TemporalFilter",
  "name":"FSL Maths TemporalFilter",
  "description":"Use fslmaths to apply a low, high, or bandpass temporal filter to a timeseries.",
}
{
  "interface":"nipype.interfaces.fsl.utils.CopyGeom",
  "name":"FSL Utils CopyGeom",
  "description":"Use fslcpgeom to copy the header geometry information to another image. Copy certain parts of the header information (image dimensions, voxel dimensions, voxel dimensions units string, image orientation/origin or qform/sform info) from one image to another. Note that only copies from Analyze to Analyze or Nifti to Nifti will work properly. Copying from different files will result in loss of information or potentially incorrect settings.",
}
{
  "interface":"nipype.interfaces.fsl.utils.RobustFOV",
  "name":"FSL Utils RobustFOV",
  "description":"Automatically crops an image removing lower head and neck.",
}
{
  "interface":"nipype.interfaces.fsl.utils.ImageMeants",
  "name":"FSL Utils ImageMeants",
  "description":"Use fslmeants for printing the average timeseries (intensities) to the screen (or saves to a file). The average is taken over all voxels in the mask (or all voxels in the image if no mask is specified)",
}
{
  "interface":"nipype.interfaces.fsl.utils.Smooth",
  "name":"FSL Utils Smooth",
  "description":"Use fslmaths to smooth the image",
}
{
  "interface":"nipype.interfaces.fsl.utils.Slice",
  "name":"FSL Utils Slice",
  "description":"Use fslslice to split a 3D file into lots of 2D files (along z-axis).",
}
{
  "interface":"nipype.interfaces.fsl.utils.Merge",
  "name":"FSL Utils Merge",
  "description":"Use fslmerge to concatenate images. Images can be concatenated across time, x, y, or z dimensions. Across the time (t) dimension the TR is set by default to 1 sec.",
}
{
  "interface":"nipype.interfaces.fsl.utils.Split",
  "name":"FSL Utils Split",
  "description":"Uses FSL Fslsplit command to separate a volume into images in time, x, y or z dimension.",
}
{
  "interface":"nipype.interfaces.fsl.utils.ImageMaths",
  "name":"FSL Utils ImageMaths",
  "description":"Use FSL fslmaths command to allow mathematical manipulation of images. `FSL info <http://www.fmrib.ox.ac.uk/fslcourse/lectures/practicals/intro/index.htm#fslutils>`_",
}
{
  "interface":"nipype.interfaces.fsl.utils.FilterRegressor",
  "name":"FSL Utils FilterRegressor",
  "description":"Data de-noising by regressing out part of a design matrix. Uses simple OLS regression on 4D images",
}
{
  "interface":"nipype.interfaces.fsl.utils.ImageStats",
  "name":"FSL Utils ImageStats",
  "description":"Use FSL fslstats command to calculate stats from images. `FSL info <http://www.fmrib.ox.ac.uk/fslcourse/lectures/practicals/intro/index.htm#fslutils>`_",
}
{
  "interface":"nipype.interfaces.fsl.utils.AvScale",
  "name":"FSL Utils AvScale",
  "description":"Use FSL avscale command to extract info from mat file output of FLIRT",
}
{
  "interface":"nipype.interfaces.fsl.utils.AvScale",
  "name":"FSL Utils AvScale",
  "description":"Use FSL avscale command to extract info from mat file output of FLIRT",
}
{
  "nipype.interfaces.fsl.preprocess.MCFLIRT": "ark:99999/fa674965-b5e3-4d8e-a91e-ec2e0d271fd1",
  "nipype.interfaces.io.SelectFiles": "ark:99999/efd11415-d084-4538-bdf1-72bd56f5af28",
  "nipype.interfaces.fsl.utils.ExtractROI": "ark:99999/56227f87-678e-4949-a244-5d10cfb21470",
  "nipype.interfaces.fsl.preprocess.SliceTimer": "ark:99999/dd4013ac-90e3-45c5-b327-3776fd43b8f2",
  "nipype.algorithms.rapidart.ArtifactDetect": "ark:99999/64b444ec-78d4-4eb3-a827-ccd99c835aeb",
  "nipype.interfaces.fsl.preprocess.BET": "ark:99999/e599b3df-bfa8-4a9a-b549-d25ac44bad9f",
  "nipype.interfaces.fsl.preprocess.FLIRT": "ark:99999/872b0559-cafd-44bc-9987-724600b5c32d",
  "nipype.interfaces.fsl.preprocess.FAST": "ark:99999/2086faa6-b61d-4c87-9df0-f7e01f2be30e",
  "nipype.interfaces.fsl.maths.Threshold": "ark:99999/f53048eb-35d6-400b-b47c-6c2aba6d84d6",
  "nipype.interfaces.io.DataSink": "ark:99999/c277082a-23b5-4a85-9035-eb8f633f0fb9",
  "nipype.interfaces.spm.preprocess.Smooth": "ark:99999/afb06b2f-23a6-4110-b5e0-ab60ddb8b80c",
  "nipype.algorithms.modelgen.SpecifySPMModel": "ark:99999/45ec28ed-cda8-482d-8762-a94edb3ebe07",
  "nipype.interfaces.spm.model.EstimateContrast": "ark:99999/f20f94c1-516e-4fde-bafd-b9142fa5d91a",
  "nipype.interfaces.spm.model.Level1Design": "ark:99999/f1220f2e-655e-460f-9749-220f29094747",
  "nipype.interfaces.utility.wrappers.Function": "ark:99999/8d6125df-b62d-4886-9d11-d2f5d2a1b5c3",
}
